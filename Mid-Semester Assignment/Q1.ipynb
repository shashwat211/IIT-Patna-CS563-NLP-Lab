{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Automatic Spelling Corrector\n",
        "We will be building an automated spelling corrector using **Hidden Markov Model** of first-order, ie _**bigram**_ dependency assumption."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Required Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6IYSK6K1vxrK"
      },
      "outputs": [],
      "source": [
        "from nltk.util import ngrams\n",
        "from tabulate import tabulate\n",
        "from collections import defaultdict, Counter\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nyxL8YHwdu_"
      },
      "source": [
        "### Preparing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2ds6XrnSwhAc"
      },
      "outputs": [],
      "source": [
        "def read_data(file_name):\n",
        "    file = open(file_name, 'r')\n",
        "    data = []\n",
        "    word = []\n",
        "    while True:\n",
        "        line = file.readline()\n",
        "        if not line:\n",
        "            break\n",
        "        line = line.strip()\n",
        "        line = line.split(',')\n",
        "        if line[0] == '_':\n",
        "            data.append(word)\n",
        "            word = []\n",
        "            continue\n",
        "        word.append(line)\n",
        "    \n",
        "    return data\n",
        "\n",
        "train_data = read_data('./train_data.txt')\n",
        "test_data = read_data('./test_data.txt')        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of train samples : 9279\n",
            "Number of test samples : 1879\n"
          ]
        }
      ],
      "source": [
        "print(f'Number of train samples : {len(train_data)}')\n",
        "print(f'Number of test samples : {len(test_data)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hidden Markov Model\n",
        "The model is bigram (first order) without any emission context."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "class HMM:\n",
        "    LAPLACE = 0.0000001\n",
        "    def __init__(self, train):\n",
        "        self.state_list = ['*'] + list(set([token[1] for sequence in train for token in sequence])) + ['STOP']\n",
        "        self.transition = self.generate_transition_matrix(train, ngram=2)\n",
        "        self.emission = self.generate_emission_matrix(train, with_context=False)\n",
        "    \n",
        "    def generate_transition_matrix(self, train, ngram=2, laplace_factor=LAPLACE):\n",
        "        y = [[token[1] for token in sequence] for sequence in train]\n",
        "        ngram_tags = []\n",
        "        for tag_list in y:\n",
        "            tag_list = [\"*\"] * (ngram - 1) + tag_list + [\"STOP\"]\n",
        "            ngram_tags.extend(ngrams(tag_list, ngram))\n",
        "        ngram_count = dict(Counter(ngram_tags))\n",
        "\n",
        "        n_minus_1_gram_tags = []\n",
        "        for tag_list in y:\n",
        "            tag_list = [\"*\"] * (ngram - 1) + tag_list + [\"STOP\"]\n",
        "            n_minus_1_gram_tags.extend(ngrams(tag_list, ngram - 1))\n",
        "        n_minus_1_gram_count = dict(Counter(n_minus_1_gram_tags))\n",
        "\n",
        "        transition_matrix = defaultdict(lambda: laplace_factor)\n",
        "\n",
        "        for ngram_tuple in ngram_count:\n",
        "            n_minus_1_gram_tuple = ngram_tuple[:-1]\n",
        "            transition_matrix[ngram_tuple] = ngram_count[ngram_tuple] / n_minus_1_gram_count[n_minus_1_gram_tuple]\n",
        "\n",
        "        return transition_matrix\n",
        "\n",
        "    def generate_emission_matrix(self, train, with_context=False, laplace_factor=LAPLACE):\n",
        "        x = [[token[0] for token in sequence] for sequence in train]\n",
        "        y = [[token[1] for token in sequence] for sequence in train]\n",
        "        word_tag_count = defaultdict(lambda: 0)\n",
        "        tag_count = defaultdict(lambda: 0)\n",
        "\n",
        "        for line, tags in zip(x, y):\n",
        "            prev_tag = '*'\n",
        "            for word, tag in zip(line, tags):\n",
        "                if with_context:\n",
        "                    tag_count[(tag, prev_tag)] += 1\n",
        "                    word_tag_count[(word, tag, prev_tag)] += 1\n",
        "                else:\n",
        "                    tag_count[(tag,)] += 1\n",
        "                    word_tag_count[(word, tag)] += 1\n",
        "                prev_tag = tag\n",
        "                \n",
        "        \n",
        "        emission_matrix = defaultdict(lambda: laplace_factor)\n",
        "        \n",
        "        for word_tags in word_tag_count.keys():\n",
        "            tags = word_tags[1:]\n",
        "            emission_matrix[word_tags] = word_tag_count[word_tags] / tag_count[tags]\n",
        "\n",
        "        return emission_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### The Viterbi Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def kappa(position, state_list):\n",
        "    return state_list if position not in [0, -1] else ['*']\n",
        "\n",
        "def viterbi(word, hmm):\n",
        "    pi = defaultdict(lambda: 0)\n",
        "    bp = defaultdict(lambda: \"OTH\")\n",
        "    pi[(0, '*')] = 1.0\n",
        "    A = hmm.transition\n",
        "    B = hmm.emission\n",
        "    state_list = hmm.state_list\n",
        "\n",
        "    n = len(word)\n",
        "\n",
        "    for k in range(1, n + 1):\n",
        "        u_set = kappa(k - 1, state_list)\n",
        "        v_set = kappa(k, state_list)\n",
        "\n",
        "        for v in v_set:\n",
        "            for u in u_set:\n",
        "                reach_prob = pi[(k - 1, u)] * A[(u, v)] * B[(word[k - 1], v)]\n",
        "                if reach_prob > pi[(k, v)]:\n",
        "                    pi[(k, v)] = reach_prob\n",
        "                    bp[(k, v)] = u\n",
        "    \n",
        "    v_set = kappa(n, state_list)\n",
        "    result_tags = []\n",
        "    if n > 0:\n",
        "        for v in v_set:\n",
        "            if len(result_tags) == 0:\n",
        "                result_tags = [v]\n",
        "            if pi[(n, v)] * A[(v, 'STOP')] > \\\n",
        "            pi[(n, result_tags[0])] * A[(result_tags[0], 'STOP')]:\n",
        "                result_tags = [v]\n",
        "    \n",
        "    for k in range(n - 1, 0, -1):\n",
        "        result_tags.append(bp[(k + 1, result_tags[-1])])\n",
        "    \n",
        "    result_tags.reverse()\n",
        "\n",
        "    return result_tags"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Testing and Evaluation\n",
        "We report the overall accuracy of the model and the class-wise (alphabet-wise) precision, recall and f1 scores. The results are tabulated accordingly. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_metrics(true, pred):\n",
        "    true = [ch for word in true for ch in word]\n",
        "    pred = [ch for word in pred for ch in word]\n",
        "    classes = list(set(true))\n",
        "    classes.sort()\n",
        "    # accuracy: (tp + tn) / (p + n)\n",
        "    acc = accuracy_score(true, pred)\n",
        "    # precision tp / (tp + fp)\n",
        "    precision = precision_score(true, pred, average=None)\n",
        "    # recall: tp / (tp + fn)\n",
        "    recall = recall_score(true, pred, average=None)\n",
        "    # f1: 2 tp / (2 tp + fp + fn)\n",
        "    f1 = f1_score(true, pred, average=None)\n",
        "\n",
        "    return acc, precision, recall, f1, classes\n",
        "\n",
        "def print_metrics(test_acc, precision, recall, f1, classes):\n",
        "    print(f\"Accuracy of the model: {test_acc}\")\n",
        "    print(tabulate(zip(classes, precision, recall, f1),\n",
        "                   headers=['Class (Alphabet)', 'Precision', 'Recall', 'F1'],\n",
        "                   tablefmt='orgtbl'))\n",
        "\n",
        "def test_and_evaluate(hmm, test_data):\n",
        "    test = [[token[0] for token in sequence] for sequence in test_data]\n",
        "    true = [[token[1] for token in sequence] for sequence in test_data]\n",
        "    pred = []\n",
        "\n",
        "    for word in test:\n",
        "        pred.append(viterbi(word, hmm))\n",
        "    \n",
        "    predictions_file = open(\"predictions.txt\", \"w\")\n",
        "    for predicted_spelling, true_spelling in zip(pred, true):\n",
        "        for pred_ch, true_ch in zip(predicted_spelling, true_spelling):\n",
        "            predictions_file.write(f'{pred_ch},{true_ch}\\n')\n",
        "        predictions_file.write(f'_,_\\n')\n",
        "\n",
        "    accuracy, precision, recall, f1, classes = evaluate_metrics(true, pred)\n",
        "    print_metrics(accuracy, precision, recall, f1, classes)          \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the model: 0.9195359281437125\n",
            "| Class (Alphabet)   |   Precision |   Recall |       F1 |\n",
            "|--------------------+-------------+----------+----------|\n",
            "| a                  |    0.931884 | 0.946981 | 0.939372 |\n",
            "| b                  |    0.775862 | 0.75     | 0.762712 |\n",
            "| c                  |    0.943231 | 0.927039 | 0.935065 |\n",
            "| d                  |    0.92233  | 0.904762 | 0.913462 |\n",
            "| e                  |    0.922249 | 0.932285 | 0.92724  |\n",
            "| f                  |    0.836478 | 0.869281 | 0.852564 |\n",
            "| g                  |    0.921569 | 0.859756 | 0.88959  |\n",
            "| h                  |    0.923304 | 0.928783 | 0.926036 |\n",
            "| i                  |    0.918728 | 0.943739 | 0.931065 |\n",
            "| j                  |    0.888889 | 1        | 0.941176 |\n",
            "| k                  |    0.893258 | 0.913793 | 0.903409 |\n",
            "| l                  |    0.912903 | 0.918831 | 0.915858 |\n",
            "| m                  |    0.931174 | 0.888031 | 0.909091 |\n",
            "| n                  |    0.908705 | 0.928416 | 0.918455 |\n",
            "| o                  |    0.954151 | 0.945946 | 0.950031 |\n",
            "| p                  |    0.871345 | 0.851429 | 0.861272 |\n",
            "| q                  |    0.666667 | 0.666667 | 0.666667 |\n",
            "| r                  |    0.927602 | 0.919283 | 0.923423 |\n",
            "| s                  |    0.915929 | 0.9      | 0.907895 |\n",
            "| t                  |    0.93588  | 0.937158 | 0.936519 |\n",
            "| u                  |    0.90429  | 0.916388 | 0.910299 |\n",
            "| v                  |    0.878788 | 0.892308 | 0.885496 |\n",
            "| w                  |    0.921875 | 0.859223 | 0.889447 |\n",
            "| x                  |    0.714286 | 0.625    | 0.666667 |\n",
            "| y                  |    0.889313 | 0.910156 | 0.899614 |\n",
            "| z                  |    0.764706 | 0.866667 | 0.8125   |\n"
          ]
        }
      ],
      "source": [
        "hmm = HMM(train_data)\n",
        "test_and_evaluate(hmm, test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Working on the given case of spelling errors\n",
        "The following sentence (P1) was given with the highlighted wrong words. The corrected words are shown in the sentence P2.  \n",
        "  \n",
        "_P1:_ star wars is **ploying** at **thi** regal lloyd **center** and imax multnomah st portland **ang** also at **tho** **centupy** eastport plaza **wuuld** any of **thoss** times **wurk** for **yoz**  \n",
        "  \n",
        "_P2:_ star wars is **playing** at **the** regal lloyd **centre** and imax multnomah st portland\n",
        "**and** also at **the** **century** eastport plaza **would** any of **those** times **work** for **you**  \n",
        "  \n",
        "We create a string of these wrong words and evaluate these words according to our viterbi algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Corrected Spelling: century\n",
            "Corrected Spelling: would\n",
            "Corrected Spelling: you\n",
            "Percentage corrected spellings: 30.0%\n"
          ]
        }
      ],
      "source": [
        "sentence = \"ploying thi center ang tho centupy wuuld thoss wurk yoz\".split()\n",
        "correct_sentence = \"playing the centre and the century would those work you\".split()\n",
        "sentence = [list(word) for word in sentence]\n",
        "\n",
        "total_errors = len(correct_sentence)\n",
        "correct_predictions = 0\n",
        "for i, word in enumerate(sentence):\n",
        "    pred_spelling = ''.join(viterbi(word, hmm))\n",
        "    if correct_sentence[i] == pred_spelling:\n",
        "        print(f'Corrected Spelling: {pred_spelling}')\n",
        "        correct_predictions += 1\n",
        "\n",
        "print(f'Percentage corrected spellings: {correct_predictions * 100 / total_errors}%')\n",
        "    \n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "CS563 NLP Midsem.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
